{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Steps of the pipeline in this notebook:\n",
    "\n",
    "1. Load raw data\n",
    "2. Create preprocessed data\n",
    "3. Get predictions of a model\n",
    "4. Dimensionality reduction (U-MAP)\n",
    "5. Find cluster of interest of FN in dimensionality reduction space\n",
    "6. Plot the cluster of interest in raw data space"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "128f957669e341b2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "random_seed = 10"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-13T10:32:38.294864400Z",
     "start_time": "2024-06-13T10:32:38.130442Z"
    }
   },
   "id": "1f5d19ee5799d0be",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 136070 rows with values > 1800 or are duplicate\n",
      "Balanced dataset: 109272 samples in total\n"
     ]
    }
   ],
   "source": [
    "# 1. Load raw data\n",
    "\n",
    "def load_all_partitions(directory):\n",
    "    all_files = glob.glob(os.path.join(directory, '*.csv'))\n",
    "    df_list = [pd.read_csv(file) for file in all_files]\n",
    "    return pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "x_raw = load_all_partitions('data/AF-Raw-Data/AF Data/all_raw_data_csv')\n",
    "\n",
    "# Remove rows that are duplicates or have values > 1800\n",
    "n_before = x_raw.shape[0]\n",
    "x_raw = x_raw.drop_duplicates()\n",
    "x_raw = x_raw[(x_raw.T < 1800).all()]\n",
    "print(f\"Removed {n_before - x_raw.shape[0]} rows with values > 1800 or are duplicate\")\n",
    "\n",
    "# Balance the dataset, by taking the same number of samples from each class\n",
    "class_1 = x_raw[x_raw['Class_Label'] == 1]\n",
    "class_0 = x_raw[x_raw['Class_Label'] == 0].sample(len(class_1), random_state=random_seed)\n",
    "x_raw = pd.concat([class_1, class_0])\n",
    "print(f\"Balanced dataset: {x_raw.shape[0]} samples in total\")\n",
    "\n",
    "x_raw.reset_index(drop=True, inplace=True)\n",
    "x_raw['Sample_id'] = x_raw.index\n",
    "\n",
    "# Split the class label from the features and split the data into train and test\n",
    "y_raw = x_raw[['Class_Label', 'Sample_id']]\n",
    "x_raw = x_raw.drop(columns=['Class_Label'])\n",
    "x_raw_train, x_raw_test, y_train, y_test = train_test_split(x_raw, y_raw, test_size=0.2, random_state=random_seed)"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-13T10:28:28.235797500Z",
     "start_time": "2024-06-13T10:28:17.920423200Z"
    }
   },
   "id": "initial_id",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 2. Create preprocessed data\n",
    "\n",
    "# 30 bins (of 50 milliseconds) are created covering R-R intervals of 200 ms up to 1700 ms. For each\n",
    "#sample the frequency of an R-R interval occurring in a certain bin was counted.\n",
    "\n",
    "# Function to bin and count intervals for a row\n",
    "def bin_row(row, bin_edges):\n",
    "    intervals = row[:-1].values # Exclude the class label from binning\n",
    "    bin_indices = np.digitize(intervals, bins=bin_edges, right=False)\n",
    "    bin_counts = np.bincount(bin_indices, minlength=len(bin_edges)+1)[1:-1]  # Exclude counts outside defined bins\n",
    "    return bin_counts\n",
    "\n",
    "def preprocess_into_bins(x_data, y_data):\n",
    "    # Define the edges of the bins\n",
    "    bin_edges = np.arange(200, 1751, 50) #ms\n",
    "    \n",
    "    x_bins = x_data.apply(lambda row: bin_row(row, bin_edges), axis=1, result_type='expand')\n",
    "    x_bins.columns = [f'bin_{i + 1}' for i in range(len(bin_edges) - 1)]\n",
    "    # x_bins['Class_Label'] = x_data['Class_Label']\n",
    "    x_bins['Sample_id'] = x_data['Sample_id']\n",
    "    return x_bins\n",
    "\n",
    "x_bins_train = preprocess_into_bins(x_raw_train, y_train)\n",
    "x_bins_test = preprocess_into_bins(x_raw_test, y_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-13T10:28:36.207008100Z",
     "start_time": "2024-06-13T10:28:28.241485500Z"
    }
   },
   "id": "bab3a55034417d30",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass-multioutput and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 12\u001B[0m\n\u001B[0;32m      9\u001B[0m svm\u001B[38;5;241m.\u001B[39mfit(x_bins_train_scaled, y_train[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mClass_Label\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m     10\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m svm\u001B[38;5;241m.\u001B[39mpredict(x_bins_test_scaled)\n\u001B[1;32m---> 12\u001B[0m acc_svm \u001B[38;5;241m=\u001B[39m \u001B[43maccuracy_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     13\u001B[0m f1_svm \u001B[38;5;241m=\u001B[39m f1_score(y_test, y_pred)\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAccuracy: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00macc_svm\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, F1: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mf1_svm\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:192\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    187\u001B[0m validate_parameter_constraints(\n\u001B[0;32m    188\u001B[0m     parameter_constraints, params, caller_name\u001B[38;5;241m=\u001B[39mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\n\u001B[0;32m    189\u001B[0m )\n\u001B[0;32m    191\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 192\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    193\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    194\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[0;32m    195\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[0;32m    196\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[0;32m    197\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[0;32m    198\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[0;32m    199\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    200\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    201\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[0;32m    202\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:221\u001B[0m, in \u001B[0;36maccuracy_score\u001B[1;34m(y_true, y_pred, normalize, sample_weight)\u001B[0m\n\u001B[0;32m    155\u001B[0m \u001B[38;5;124;03m\"\"\"Accuracy classification score.\u001B[39;00m\n\u001B[0;32m    156\u001B[0m \n\u001B[0;32m    157\u001B[0m \u001B[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    217\u001B[0m \u001B[38;5;124;03m0.5\u001B[39;00m\n\u001B[0;32m    218\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    220\u001B[0m \u001B[38;5;66;03m# Compute accuracy for each possible representation\u001B[39;00m\n\u001B[1;32m--> 221\u001B[0m y_type, y_true, y_pred \u001B[38;5;241m=\u001B[39m \u001B[43m_check_targets\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    222\u001B[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001B[0;32m    223\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y_type\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultilabel\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:95\u001B[0m, in \u001B[0;36m_check_targets\u001B[1;34m(y_true, y_pred)\u001B[0m\n\u001B[0;32m     92\u001B[0m     y_type \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulticlass\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n\u001B[0;32m     94\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(y_type) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m---> 95\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m     96\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mClassification metrics can\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt handle a mix of \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m and \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m targets\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m     97\u001B[0m             type_true, type_pred\n\u001B[0;32m     98\u001B[0m         )\n\u001B[0;32m     99\u001B[0m     )\n\u001B[0;32m    101\u001B[0m \u001B[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001B[39;00m\n\u001B[0;32m    102\u001B[0m y_type \u001B[38;5;241m=\u001B[39m y_type\u001B[38;5;241m.\u001B[39mpop()\n",
      "\u001B[1;31mValueError\u001B[0m: Classification metrics can't handle a mix of multiclass-multioutput and binary targets"
     ]
    }
   ],
   "source": [
    "# 3. Get predictions of a model\n",
    "\n",
    "# Normalise using standard scaler\n",
    "scaler = StandardScaler()\n",
    "x_bins_train_scaled = scaler.fit_transform(x_bins_train.drop(columns=['Sample_id']))\n",
    "x_bins_test_scaled = scaler.transform(x_bins_test.drop(columns=['Sample_id']))\n",
    "\n",
    "svm = SVC(random_state=random_seed, kernel='rbf')\n",
    "svm.fit(x_bins_train_scaled, y_train['Class_Label'])\n",
    "y_pred = svm.predict(x_bins_test_scaled)\n",
    "\n",
    "acc_svm = accuracy_score(y_test['Class_Label'], y_pred)\n",
    "f1_svm = f1_score(y_test['Class_Label'], y_pred)\n",
    "\n",
    "print(f\"Accuracy: {round(acc_svm,4)}, F1: {round(f1_svm,4)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-13T10:36:17.185873500Z",
     "start_time": "2024-06-13T10:32:42.050403500Z"
    }
   },
   "id": "423f1b09b218bad",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.953, F1: 0.9531\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-13T10:37:08.719153100Z",
     "start_time": "2024-06-13T10:37:08.695782100Z"
    }
   },
   "id": "6fc142909bed67f0",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8f9f91ee8200c4a5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
